{"metadata":{"colab":{"provenance":[],"collapsed_sections":["DsnYiVKspyTa","RzS2jPL-p7JY","i5ouWy92YIxD","NnJvgIwGEmIh"],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30762,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport keras\nimport random\n\nimport numpy as np\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import train_test_split","metadata":{"id":"c_0h3LSdGwrG","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"SEED       = 68857869\nBATCH_SIZE = 32\nIMG_WIDTH  = 64\nIMG_HEIGHT = 64\nBETA       = 0.9\n\nrandom.seed(SEED)\ntf.random.set_seed(SEED)\nnp.random.seed(SEED)","metadata":{"id":"5P1GYfqvc_BP","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Dataset Download and Preparation","metadata":{"id":"DsnYiVKspyTa"}},{"cell_type":"code","source":"#!wget http://cs231n.stanford.edu/tiny-imagenet-200.zip\n#!unzip tiny-imagenet-200.zip\n#!mkdir images\n!find tiny-imagenet-200 -type f -name '*.JPEG' -exec mv {} images \\;\n!ls images | wc -l\n!mkdir -p cache","metadata":{"id":"w6i6ZGOLnCPL","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Data Loading and Preprocessing","metadata":{"id":"RzS2jPL-p7JY"}},{"cell_type":"code","source":"def decode_img(img,img_width,img_height):\n  img = tf.io.read_file(img)\n  img = tf.io.decode_jpeg(img, channels=3)\n  return tf.image.resize(img, [img_width,img_height])\n\n\ndef datapipe(files,batch_size,img_width,img_height,name):\n  cover = tf.data.Dataset.from_tensor_slices(files)\n  cover = cover.map(lambda x: decode_img(x,img_width,img_height))\n\n  random.shuffle(files)\n\n  payload = tf.data.Dataset.from_tensor_slices(files)\n  payload = payload.map(lambda x: decode_img(x,img_width,img_height))\n\n  data = tf.data.Dataset.zip(cover,payload)\n  ds = tf.data.Dataset.zip(data,data)\n\n  ds = ds.batch(batch_size).cache()\n  ds = ds.prefetch(tf.data.AUTOTUNE)\n  return ds\n\nfiles       = [f\"images/{_file}\" for _file in os.listdir('images')]\ntrain , val = train_test_split(files,train_size=0.7)\n\nbatch_size=32\n\ntrain_dataset = datapipe(train,batch_size,64,64,'train')\nval_dataset   = datapipe(val,batch_size,64,64,'val')","metadata":{"id":"upJp8L7wX-DX","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for target,predict in train_dataset.take(2):\n    cover = target[0][0].numpy().astype(\"uint8\")\n    payload = target[1][0].numpy().astype(\"uint8\")\n\n    fig, ax = plt.subplots(1, 4, figsize=(9, 5))\n\n    ax[0].imshow(cover)\n    ax[0].set_title('In-Cover')\n    ax[0].axis('off')\n\n    ax[1].imshow(payload)\n    ax[1].set_title('In-Payload')\n    ax[1].axis('off')\n\n    cover = predict[0][0].numpy().astype(\"uint8\")\n    payload = predict[1][0].numpy().astype(\"uint8\")\n\n    ax[2].imshow(cover)\n    ax[2].set_title('Target-Cover')\n    ax[2].axis('off')\n\n    ax[3].imshow(payload)\n    ax[3].set_title('Target-Payload')\n    ax[3].axis('off')\n\n    plt.show()","metadata":{"id":"eNMO_qa2XRR9","colab":{"base_uri":"https://localhost:8080/","height":403},"outputId":"e25389c8-8d33-4b82-badd-7be050e74370","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Model Definition","metadata":{"id":"i5ouWy92YIxD"}},{"cell_type":"code","source":"def conv_layer(x, num_filters, activation='relu', name='conv_layer'):\n    x = keras.layers.Conv2D(num_filters, (3, 3), padding='same', name=f'{name}_conv')(x)\n    x = keras.layers.BatchNormalization(name=f'{name}_bn')(x)\n    x = keras.layers.Activation(activation, name=f'{name}_act')(x)\n    return x\n\ndef encoder():\n    cover_input = keras.Input(shape=(64, 64, 3), name='cover_input')\n    payload_input = keras.Input(shape=(64, 64, 3), name='payload_input')\n\n    conc_layer = keras.layers.Concatenate(name='concat_cover_payload')([cover_input, payload_input])\n\n    l1 = conv_layer(conc_layer, 64, name='encoder_l1')\n    l2 = conv_layer(l1, 128, name='encoder_l2')\n    l3 = conv_layer(l2, 256, name='encoder_l3')\n    l4 = conv_layer(l3, 512, name='encoder_l4')\n    l5 = conv_layer(l4, 512, name='encoder_l5')\n\n    x = keras.layers.Concatenate(name='concat_l3_l5')([l3, l5])\n    l6 = conv_layer(x, 256, name='encoder_l6')\n\n    x = keras.layers.Concatenate(name='concat_l2_l6')([l2, l6])\n    l7 = conv_layer(x, 128, name='encoder_l7')\n\n    x = keras.layers.Concatenate(name='concat_l1_l7')([l1, l7])\n    l8 = conv_layer(x, 64, name='encoder_l8')\n\n    steg_image = conv_layer(l8, 3, activation='sigmoid', name='encoder_output')\n\n    encoder_model = keras.Model(inputs=[cover_input, payload_input], outputs=steg_image, name='encoder')\n    return encoder_model\n\ndef decoder():\n    steg_input = keras.layers.Input(shape=(64, 64, 3), name='steg_image_input')\n    x = conv_layer(steg_input, 64, name='decoder_l1')\n    x = conv_layer(x, 128, name='decoder_l2')\n    x = conv_layer(x, 256, name='decoder_l3')\n    x = conv_layer(x, 128, name='decoder_l4')\n    x = conv_layer(x, 64, name='decoder_l5')\n    x = conv_layer(x, 3, activation='sigmoid', name='decoder_output')\n\n    decoder_model = keras.Model(inputs=steg_input, outputs=x, name='decoder')\n    return decoder_model","metadata":{"id":"Ms10GFQWYLT1","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cover_input = keras.Input(shape=(64, 64, 3), name='cover_input')\npayload_input = keras.Input(shape=(64, 64, 3), name='payload_input')\n\nencoder_model = encoder()\ndecoder_model = decoder()\n\nsteg_image    = encoder_model([cover_input, payload_input])\npayload_image = decoder_model(steg_image)\n\nmodel = keras.Model(inputs=[cover_input, payload_input], outputs=[steg_image,payload_image], name='steg_model')\nmodel.summary()","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":306},"id":"4cglYp6_b35X","outputId":"d29f3558-c857-47d1-e5d1-842633e6ea4a","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Loss and Metric functions","metadata":{"id":"NnJvgIwGEmIh"}},{"cell_type":"code","source":"def steg_loss(true,pred):\n  l2_loss   = keras.losses.mean_squared_error(true,pred)\n  ssim_loss = 1 - tf.reduce_mean(tf.image.ssim(target, pred, 1.0))\n\n  return l2_loss + (0.6 * ssim_loss)","metadata":{"id":"4B298QDtyzmP","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Training\n","metadata":{"id":"W5ip_V0UUS1_"}},{"cell_type":"code","source":"model.compile(\n    optimizer='adam',\n    loss=[steg_loss,steg_loss],\n    loss_weights=[1,BETA])","metadata":{"id":"TwuBpFqiUUrm","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.fit(train_dataset, epochs=10, validation_data=val_dataset)","metadata":{"id":"9SQ86YQAUkmP","trusted":true},"execution_count":null,"outputs":[]}]}